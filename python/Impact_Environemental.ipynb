{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judelo/algosto/blob/master/Impact_Environemental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mesure de l'impact environmental du Machine Learning"
      ],
      "metadata": {
        "id": "XYgSCQFfK50i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Dans ce TP, on va tenter de mesurer l'impact environnemental d'outils standards de Machine Learning. On va utiliser pour cela deux outils différents. Le premier est le site  https://www.green-algorithms.org qui permet de mesurer une partie des gaz à effet de serre liés aux calculs numériques. Pour utiliser cet outil, il faut lui fournir plusieurs types de données sur les conditions de calcul (type de CPU, GPU, lieu du serveur etc). On va voir comment trouver ces informations. \n",
        "\n",
        "Ensuite, nous utiliserons la librairie python CodeCarbon pour mesurer l'impact de nos calculs directement à l'intérieur de Python. Nous comparerons les valeurs obtenues avec celles données par green-algorithms.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l9SoVI2PIw_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Green Algorithms\n",
        "\n",
        "Cette section explique comment collecter les données nécessaires à l'utilisation du site. Comme certaines des données nécessaires sont liées au matériel, nous expliquerons comment obtenir ces informations en fonction du système d'exploitation. N'oubliez pas que Google Colab fonctionne sur des machines virtuelles Linux.\n"
      ],
      "metadata": {
        "id": "uEIxT5ezMMGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type, nombre, modèles et coeurs\n",
        "\n",
        "Si vous utilisez  Colab, vous pouvez choisir de faire tourner votre code sur CPU, GPU ou TPU dans **Exécution > Modifier le type d'exécution**.\n",
        "\n",
        "Pour connaître le CPU utilisé, vous pouvez utiliser les commandes suivantes : \n",
        "\n",
        "- **Linux**: `!lscpu` \n",
        "- **MacOS**: `sysctl -n machdep.cpu.brand_string` \n",
        "- **Windows**: `wmic cpu get name, numberofcores` \n",
        "\n"
      ],
      "metadata": {
        "id": "hpd7487rMfS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !lscpu"
      ],
      "metadata": {
        "id": "ibdkp904MpRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nombre et modèles de GPUs: \n",
        "\n",
        "- **Linux**: `lshw -C display`\n",
        "- **MacOS**: browse: **System Settings > General > About > Graphics**\n",
        "- **Windows**: browse: **Task Manager > Performance > GPU**\n",
        "\n",
        "\n",
        "**Remarque sur Colab**\n",
        "\n",
        "Si vous utilisez Colab, la commande Linux ci-dessous ne fonctionne pas, mais comme Colab utilise des GPU Nvidia, vous pouvez utiliser la commande spécifique :`!nvidia-smi -L`. "
      ],
      "metadata": {
        "id": "5le3dWPgTcdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !nvidia-smi -L"
      ],
      "metadata": {
        "id": "JT_vNH5QMk0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si le modèle de CPU (ou de GPU) n'est pas répertorié comme une valeur possible dans green-algorithms, vous pouvez utiliser la valeur de TDP (Thermal Design Power) par coeur de votre CPU (ou GPU). "
      ],
      "metadata": {
        "id": "BB2XsadONECa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mémoire disponible\n",
        "La mémoire vive est très consommatrice d'énergie. On peut utiliser l'une des commandes suivantes pour la connaître (attention si la commande retourne une valeur en Ko ou Mo il faut la convertir en Go (1 Go = 1024 Mo = 1048576 Ko)\n",
        "\n",
        "- **Linux**: `!grep MemTotal /proc/meminfo`.\n",
        "- **MacOS**: `system_profiler SPHardwareDataType | grep \"Memory:\"`. \n",
        "- **Windows**: `systeminfo | findstr /C:\"Total Physical Memory\"`. "
      ],
      "metadata": {
        "id": "5sQmMPC-OY8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!grep MemTotal /proc/meminfo"
      ],
      "metadata": {
        "id": "eRsasV6IObdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plateforme utilisée pour les calculs\n",
        "\n",
        "Il est important de déterminer sur quelle plateforme le calcul tourne : ordinateur local, serveur, centre de calcul, etc. Typiquement dans un centre de calcul ou sur un serveur, il faut tenir compte d'autres dépenses d'énergie (refroidissement, onduleurs, etc) dûes aux infrastructures.  \n",
        "\n"
      ],
      "metadata": {
        "id": "rWm8CSmtEtZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lieu\n",
        "\n",
        "Le principal facteur affectant l'empreinte carbone est le lieu où se trouve l'ordinateur ou le serveur de calcul, car l'énergie électrique ne provient pas des mêmes sources selon le pays, donc connaître ce lieu est indispensable pour évaluer les émissions de CO2 de notre calcul. \n",
        "\n",
        "On peut vérifier le lieu d'éxécution du code avec la commande  `curl ipinfo.io` (sous Linux, Windows et MacOS). Pour Colab, on peut déterminer le centre utilisé avec le [lien suivant](https://cloud.google.com/about/locations?hl=es) (ce lieu change quand vous réinitialisez le notebook).\n",
        "\n",
        "Remarque : le site green-algorithms ne tient pas compte du bilan électrique du lieu en temps réel, pour cela il faudrait utiliser [ce site](https://app.electricitymaps.com/). Les données utilisées sont issues de [ce fichier](https://github.com/GreenAlgorithms/green-algorithms-tool/blob/master/data/latest/CI_aggregated.csv), qui contient des valeurs moyennes par pays.  "
      ],
      "metadata": {
        "id": "nmrna4z1LihJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl ipinfo.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj-pS9DbMhyn",
        "outputId": "c2cc6f32-a591-4ac1-d4c1-d250b4bfbedd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ip\": \"34.126.167.239\",\n",
            "  \"hostname\": \"239.167.126.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"Singapore\",\n",
            "  \"region\": \"Singapore\",\n",
            "  \"country\": \"SG\",\n",
            "  \"loc\": \"1.2897,103.8501\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"018989\",\n",
            "  \"timezone\": \"Asia/Singapore\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Temps de calcul et cores usage factor \n",
        "\n",
        "Le *temps réel* est le temps mesuré entre le début et la fin du calcul. C'est la valeur qu'il faudra fournir comme  \"Runtime\" dans l'outil green-algorithms. \n",
        "\n",
        "Le *temps processeur* est la quantité de temps pendant laquelle un coeur (GPU, GPU ou TPU) a été utilisé.  (source: [Wikipedia](https://en.wikipedia.org/wiki/Time_(Unix)))\n",
        "\n",
        "$$\n",
        "\\text{Process time} = \\text{user time} + \\text{system time}\n",
        "$$\n",
        "\n",
        "Le cores usage factor est le pourcentage de coeurs disponibles utilisés par le calcul \n",
        "$$\n",
        "  \\text{Usage factor} = \\frac{\\text{Process time}}{(\\text{Real time * number of cores})}\n",
        "$$\n",
        "\n",
        "Nous pouvons mesurer le temps de traitement des CPUs et le temps réel passé par le code grâce à la commande `time` (sur Linux et MacOS). Malheureusement, il n'existe pas de commande similaire pour Windows. Il sera nécessaire d'utiliser des bibliothèques spécifiques comme `psutil` pour Python. Nous allons voir un exemple ci-dessous. \n",
        "\n",
        "**Question 1: Donnez des exemples où le temps réel peut être supérieur au temps de traitement processeur, et vice versa.**"
      ],
      "metadata": {
        "id": "JrzmTx5PY3O3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exemple pour mesurer le temps réel et le temps processeur.\n",
        "\n",
        "Nous allons utiliser dans ce TP comme exemple de calcul typique un réseau profond pré-entraîné pour le débruitage d'images, présenté dans [Tassano et al, An Analysis and Implementation of the FFDNet Image Denoising Method, IPOL, 2019](https://www.ipol.im/pub/art/2019/231/?utm_source=doi). \n",
        "\n",
        "On commence par télécharger le code et le modèle. On installe aussi tous les paquets requis par le script. Ils sont listés dans `requirements.txt` et peuvent être installés grâce à la ligne commentée ci-dessous. Si vous utilisez Google colab, l'exécution de cette ligne n'est pas nécessaire, puisque presque toutes les exigences sont déjà remplies, mais si vous exécutez localement, décommentez la ligne.\n"
      ],
      "metadata": {
        "id": "zX2Gh0bK8GYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!wget -c https://www.ipol.im/pub/art/2019/231/ffdnet-pytorch.zip\n",
        "!unzip ffdnet-pytorch.zip\n",
        "#!pip install -r requirements.txt\n",
        "!pip uninstall -y imgaug albumentations\n",
        "#!pip install scikit-image==0.15.0  # sci-kit image is needed by the IPOL version of FFDnet "
      ],
      "metadata": {
        "id": "CUsBJIB28Fxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e3179c-a345-4940-8db9-a85fac379c29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-04 22:29:17--  https://www.ipol.im/pub/art/2019/231/ffdnet-pytorch.zip\n",
            "Resolving www.ipol.im (www.ipol.im)... 92.243.17.137\n",
            "Connecting to www.ipol.im (www.ipol.im)|92.243.17.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Archive:  ffdnet-pytorch.zip\n",
            "replace ffdnet-pytorch/functions.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ffdnet-pytorch/functions.py  \n",
            "replace ffdnet-pytorch/ffdnet.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ffdnet-pytorch/ffdnet.png  \n",
            "replace ffdnet-pytorch/prepare_patches.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ffdnet-pytorch/prepare_patches.py  \n",
            "replace ffdnet-pytorch/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ffdnet-pytorch/.DS_Store  \n",
            "replace ffdnet-pytorch/models.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace ffdnet-pytorch/requirements.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ffdnet-pytorch/requirements.txt  \n",
            "replace ffdnet-pytorch/models/net_gray.pth? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ffdnet-pytorch/models/net_gray.pth  \n",
            "  inflating: ffdnet-pytorch/models/net_rgb.pth  \n",
            "  inflating: ffdnet-pytorch/noisy.png  \n",
            "  inflating: ffdnet-pytorch/dataset.py  \n",
            "  inflating: ffdnet-pytorch/utils.py  \n",
            "  inflating: ffdnet-pytorch/train.py  \n",
            "  inflating: ffdnet-pytorch/README.txt  \n",
            "  inflating: ffdnet-pytorch/input.png  \n",
            "  inflating: ffdnet-pytorch/test_ffdnet_ipol.py  \n",
            "\u001b[33mWARNING: Skipping imgaug as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping albumentations as it is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ffdnet-pytorch"
      ],
      "metadata": {
        "id": "gQ-8Mjyu8oYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49657393-4f96-47f7-8dcf-b847b8e2f1ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ffdnet-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser le script `test_ffdnet_ipol.py` pour débruiter l'image `input.png`. Nous utiliserons la commande `time` pour mesurer le temps utilisé par le script, et pour obtenir le temps de calcul processeur. "
      ],
      "metadata": {
        "id": "sZEPoQK1_Sat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time python test_ffdnet_ipol.py --input input.png --add_noise True --noise_sigma 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMP-yDka8xiq",
        "outputId": "6f6fffec-c7a9-4008-f319-1e38f107ce2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Testing FFDNet model ###\n",
            "> Parameters:\n",
            "\tadd_noise: True\n",
            "\tinput: input.png\n",
            "\tsuffix: \n",
            "\tnoise_sigma: 0.19607843137254902\n",
            "\tdont_save_results: False\n",
            "\tno_gpu: False\n",
            "\tcuda: True\n",
            "\n",
            "\n",
            "rgb: True\n",
            "im shape: (518, 774, 3)\n",
            "Loading model ...\n",
            "\n",
            "\n",
            "real\t0m6.646s\n",
            "user\t0m4.161s\n",
            "sys\t0m2.546s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le temps total passé par le script correspond à la valeur 'real'. Le temps CPU sera la somme des valeurs 'user' et 'sys'. Maintenant nous allons mesurer les mêmes variables en utilisant les bibliothèques `psutil` et `time`."
      ],
      "metadata": {
        "id": "Q2w0258t7_5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "user_start = psutil.cpu_times().user\n",
        "system_start = psutil.cpu_times().system\n",
        "\n",
        "!python test_ffdnet_ipol.py --input input.png --add_noise True --noise_sigma 50\n",
        "\n",
        "end = time.time()\n",
        "user_end = psutil.cpu_times().user\n",
        "system_end = psutil.cpu_times().system\n",
        "\n",
        "print(\"real \", end - start)\n",
        "print(\"user \", user_end - user_start)\n",
        "print(\"sys \", system_end - system_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN_5-r12FMnR",
        "outputId": "949a5b22-43fe-4059-ed8d-cc7bdc2224e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Testing FFDNet model ###\n",
            "> Parameters:\n",
            "\tadd_noise: True\n",
            "\tinput: input.png\n",
            "\tsuffix: \n",
            "\tnoise_sigma: 0.19607843137254902\n",
            "\tdont_save_results: False\n",
            "\tno_gpu: False\n",
            "\tcuda: True\n",
            "\n",
            "\n",
            "rgb: True\n",
            "im shape: (518, 774, 3)\n",
            "Loading model ...\n",
            "\n",
            "real  6.536521911621094\n",
            "user  4.279999999999973\n",
            "sys  2.5900000000000034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Temps GPU\n",
        "\n",
        "Pour mesurer le temps de traitement GPU, il est nécessaire d'utiliser l'outil [NVIDIA Nsight Compute] (https://developer.nvidia.com/nsight-compute). \n",
        "\n",
        "Nous devrons additionner le temps de tous les processus hérités du script et qui utilisent le GPU. Pour faciliter la tâche, nous pouvons envoyer les données dans un fichier CSV et y effectuer une somme."
      ],
      "metadata": {
        "id": "bcGLRwZx7PfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --csv --metrics gpu__time_active  --target-processes all python test_ffdnet_ipol.py --input input.png --add_noise True --noise_sigma 50 >> gpu.csv"
      ],
      "metadata": {
        "id": "gSSAKi-th3pe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Malheureusement, il n'y a pas d'outil utilisable en ligne de commande qui nous donne à la fois le temps total du script, le temps CPU et le temps GPU.\n",
        "\n",
        "Nous pourrions ajouter dans le script `test_ffdnet_ipol.py` quelques lignes pour calculer le *temps réel*, comme montré dans l'exemple précédent. \n",
        "Pour simplifier (afin de ne pas modifier le script), nous prendrons le temps utilisé par le script comme celui indiqué dans l'exemple ci-dessus. "
      ],
      "metadata": {
        "id": "bvhKkwM9AIlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Power Usage Efficiency (PUE)\n",
        "\n",
        "Le PUE est le coefficient d'efficacité du centre de données. Si le PUE n'est pas donné, nous considérons la valeur moyenne donnée en 2020 pour les serveurs : 1.58.\n",
        "Pour les ordinateurs personnels, nous considérons PUE=1.\n",
        "\n",
        "Pour les centres de données de Google, la valeur est de 1.1 (voir https://www.google.com/about/datacenters/efficiency/)."
      ],
      "metadata": {
        "id": "yFUpv87lSLBM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PSF (Pragmatic Scaling Factor)\n",
        "\n",
        "Ce paramètre est utilisé pour indiquer combien de fois nous avons exécuté le code avec la configuration indiquée."
      ],
      "metadata": {
        "id": "MwPWpaj57KDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CodeCarbon\n",
        "\n",
        "[CodeCarbon] (https://codecarbon.io) est une librairie Python. Elle permet d'estimer la quantité d'émissions CO2 produites par l'exécution d'un code. CodeCarbon prend en compte la consommation d'énergie et la localisation du calcul pour calculer cette empreinte."
      ],
      "metadata": {
        "id": "MlGnyuE-kyPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n"
      ],
      "metadata": {
        "id": "MS8SusTX7sgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install codecarbon"
      ],
      "metadata": {
        "id": "6FoES9ILlQIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ede58ed-6024-414b-de30-9d7ef3494987"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting codecarbon\n",
            "  Downloading codecarbon-2.1.4-py3-none-any.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 18.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from codecarbon) (2.23.0)\n",
            "Collecting arrow\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from codecarbon) (5.4.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from codecarbon) (1.3.5)\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from codecarbon) (7.1.2)\n",
            "Collecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.8/dist-packages (from arrow->codecarbon) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->codecarbon) (2022.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas->codecarbon) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->codecarbon) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->codecarbon) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->codecarbon) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->codecarbon) (3.0.4)\n",
            "Installing collected packages: pynvml, py-cpuinfo, fuzzywuzzy, arrow, codecarbon\n",
            "Successfully installed arrow-1.2.3 codecarbon-2.1.4 fuzzywuzzy-0.18.0 py-cpuinfo-9.0.0 pynvml-11.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage\n",
        "\n",
        "Voir la [documentation](https://mlco2.github.io/codecarbon/usage.html) sur les différentes manières d'utiliser la librairie.\n",
        "\n",
        "Par défaut, le paquet enregistre les données dans un fichier CSV nommé `emissions.csv` dans le répertoire courant. "
      ],
      "metadata": {
        "id": "AJcbSjfm2isT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from codecarbon import EmissionsTracker\n",
        "tracker = EmissionsTracker()\n",
        "\n",
        "tracker.start()\n",
        "!python test_ffdnet_ipol.py --input input.png --add_noise True --noise_sigma 50\n",
        "emissions: float = tracker.stop()\n",
        "\n",
        "print(\"Emissions (KG CO2): \", emissions)"
      ],
      "metadata": {
        "id": "g8lanBifk1Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3461d1-ba62-4545-c836-bd12dd6efa96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 21:41:34] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 21:41:34] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 21:41:34] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 21:41:34] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 21:41:34] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 21:41:36] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 21:41:36] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 21:41:36] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 21:41:36]   Platform system: Linux-5.10.133+-x86_64-with-glibc2.27\n",
            "[codecarbon INFO @ 21:41:36]   Python version: 3.8.15\n",
            "[codecarbon INFO @ 21:41:36]   Available RAM : 12.681 GB\n",
            "[codecarbon INFO @ 21:41:36]   CPU count: 2\n",
            "[codecarbon INFO @ 21:41:36]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 21:41:36]   GPU count: 1\n",
            "[codecarbon INFO @ 21:41:36]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Testing FFDNet model ###\n",
            "> Parameters:\n",
            "\tadd_noise: True\n",
            "\tinput: input.png\n",
            "\tsuffix: \n",
            "\tnoise_sigma: 0.19607843137254902\n",
            "\tdont_save_results: False\n",
            "\tno_gpu: False\n",
            "\tcuda: True\n",
            "\n",
            "\n",
            "rgb: True\n",
            "im shape: (518, 774, 3)\n",
            "Loading model ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 21:41:42] Energy consumed for RAM : 0.000008 kWh. RAM Power : 4.755459308624268 W\n",
            "[codecarbon INFO @ 21:41:42] Energy consumed for all GPUs : 0.000052 kWh. All GPUs Power : 30.761 W\n",
            "[codecarbon INFO @ 21:41:42] Energy consumed for all CPUs : 0.000073 kWh. All CPUs Power : 42.5 W\n",
            "[codecarbon INFO @ 21:41:42] 0.000133 kWh of electricity used since the begining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emissions (KG CO2):  8.407225689846512e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Des informations sur l'infrastructure de la plateforme utilisée sont fournies en sortie. On y trouve également l'énergie consommée par les composants et les émissions calculées."
      ],
      "metadata": {
        "id": "nAudjSsA8UUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualisation\n",
        "\n",
        "Pour afficher les informations enregistrées par le tracker sur un tableau de bord, carbonboard crée un site web local sur le port 8050 (http://127.0.0.1:8050). Avec Colab, nous ne pourrons malheureusement pas accéder à cette page. \n",
        "\n",
        "Une option consiste à installer le tableau de bord sur l'ordinateur local, et à utiliser le fichier cvs créé dans Colab. Pour ce faire, il faut suivre les étapes suivantes :\n",
        "\n",
        "- Installer tous les paquets nécessaires pour le tableau de bord\n",
        "\n",
        "  ```\n",
        "  pip install codecarbon\n",
        "  pip install dash\n",
        "  pip install dash_bootstrap_components==0.13.1\n",
        "  pip install fire\n",
        "  ```\n",
        "- Téléchargez le fichier `emissions.csv` créé dans Colab.\n",
        "- Exécutez `carbonboard --filepath=\"/<location>/<of>/emissions.csv\"`.\n",
        "- Allez le site : http://127.0.0.1:8050\n",
        "\n"
      ],
      "metadata": {
        "id": "CFdMi4V9vucp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention \n",
        "\n",
        "Le suivi de l'utilisation CPU et GPU nécessite un logiciel spécifique pour chaque système d'exploitation, défini dans https://pypi.org/project/codecarbon/#cpu (rubrique *Support de l'infrastructure*).\n",
        "\n",
        "Dans le cas où le logiciel n'est pas installé, ou si l'accès aux fichiers requis ne peut être activé, une consommation moyenne est utilisée, également détaillée [ici](https://pypi.org/project/codecarbon/#cpu). Cette hypothèse peut conduire à estimer des valeurs d'émissions de carbone non réalistes."
      ],
      "metadata": {
        "id": "88PgXEdio8Fl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXERCICE A FAIRE \n",
        "\n",
        "Utilisez l'outil https://www.green-algorithms.org et la bibliothèque CodeCarbon pour calculer l'empreinte carbone correspondant à l'exécution dans Colab du script de débruitage `test_ffdnet_ipol.py ` sur `input.png`. L'outil Green-Algorithms ne permet d'utiliser que des temps d'exécution supérieurs à 1 minute, et le script ffdnet prend seulement quelques secondes pour débruiter une image.\n",
        "On va donc lancer le script 15 fois de suite, en utilisant la ligne suivante :\n",
        "\n",
        "` ! for i in {0..14} ; do python test_ffdnet_ipol.py --input input.png --add_noise True --noise_sigma 50 ; done`\n"
      ],
      "metadata": {
        "id": "fREPY4X7BGBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TO DO"
      ],
      "metadata": {
        "id": "AHCBjQkxIJFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c894fe07-1c99-4b3f-f932-24ef2d9e4e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:25:32] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 18:25:32] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 18:25:32] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 18:25:32] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 18:25:32] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 18:25:33] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 18:25:33] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 18:25:33] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 18:25:33]   Platform system: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "[codecarbon INFO @ 18:25:33]   Python version: 3.7.15\n",
            "[codecarbon INFO @ 18:25:33]   Available RAM : 12.681 GB\n",
            "[codecarbon INFO @ 18:25:33]   CPU count: 2\n",
            "[codecarbon INFO @ 18:25:33]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 18:25:33]   GPU count: 1\n",
            "[codecarbon INFO @ 18:25:33]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 18:25:40] Energy consumed for RAM : 0.000000 kWh. RAM Power : 0.062224388122558594 W\n",
            "[codecarbon INFO @ 18:25:40] Energy consumed for all GPUs : 0.000053 kWh. All GPUs Power : 29.016000000000005 W\n",
            "[codecarbon INFO @ 18:25:40] Energy consumed for all CPUs : 0.000078 kWh. All CPUs Power : 42.5 W\n",
            "[codecarbon INFO @ 18:25:40] 0.000131 kWh of electricity used since the begining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emissions (KG CO2):  1.8148471654849708e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2** : comparer les résultats fournis par CodeCarbon avec ceux obtenus par Green-Algorithms.\n",
        "\n",
        "Pouvez-vous expliquer les différences ? \n",
        "\n",
        "Il semble que CodeCarbon n'ait pas détecté que le code s'exécute sur le cloud (vérifiez-le dans le fichier `emissions.csv`), et également qu'il n'ait pas tenu compte du CPU par Colab (il a pris un TDP par défaut), d'après les messages d'erreur suivants :\n",
        "\n",
        "```\n",
        "[codecarbon WARNING @ 18:34:09] No CPU tracking mode found. Falling back on CPU constant mode.\n",
        "[codecarbon WARNING @ 18:34:10] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_EVaNTqnV2l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3**: Comment tenir compte du fait qu'on utilise un serveur dans un centre de données pour modifier le résultat de Code Carbon ?\n"
      ],
      "metadata": {
        "id": "CPMki42OmWHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**: A votre avis, quels autres facteurs devraient être ajoutés à ce calcul d'impact ?"
      ],
      "metadata": {
        "id": "EKVuZMO1lCJY"
      }
    }
  ]
}